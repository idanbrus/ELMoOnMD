{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('../')\n",
    "\n",
    "from typing import List,Dict\n",
    "from elmo_on_md.data_loaders.sentiment_loader import SentimentLoader\n",
    "from elmo_on_md.evaluation.sentiment_analysis import SentimentAnalysis\n",
    "from elmo_on_md.evaluation.model_loader import load_model\n",
    "from ELMoForManyLangs.elmoformanylangs import Embedder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = SentimentLoader()\n",
    "sentiment_data = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-25 21:01:42,287 INFO: char embedding size: 2289\n",
      "2019-08-25 21:01:43,291 INFO: word embedding size: 189561\n",
      "2019-08-25 21:01:46,713 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(189561, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(2289, 50, padding_idx=2286)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-25 21:02:05,444 INFO: 129 batches, avg len: 16.9\n",
      "2019-08-25 21:03:00,536 INFO: Finished 1000 sentences.\n",
      "2019-08-25 21:03:51,745 INFO: Finished 2000 sentences.\n",
      "2019-08-25 21:05:01,768 INFO: Finished 3000 sentences.\n",
      "2019-08-25 21:05:47,352 INFO: Finished 4000 sentences.\n",
      "2019-08-25 21:06:39,218 INFO: Finished 5000 sentences.\n",
      "2019-08-25 21:07:32,403 INFO: Finished 6000 sentences.\n",
      "2019-08-25 21:08:26,743 INFO: Finished 7000 sentences.\n",
      "2019-08-25 21:09:12,859 INFO: Finished 8000 sentences.\n",
      "2019-08-25 21:09:26,864 INFO: 33 batches, avg len: 17.2\n",
      "2019-08-25 21:10:16,553 INFO: Finished 1000 sentences.\n",
      "2019-08-25 21:11:17,102 INFO: Finished 2000 sentences.\n",
      "..\\elmo_on_md\\evaluation\\sentiment_analysis.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.softmax(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\t Train Loss: 421.77441823482513\t Validation Loss: 1.0691043138504028\n",
      "Epoch: 1\t Train Loss: 383.07359755039215\t Validation Loss: 0.9425480961799622\n",
      "Epoch: 2\t Train Loss: 348.28995341062546\t Validation Loss: 0.8777016997337341\n",
      "Epoch: 3\t Train Loss: 325.8949926495552\t Validation Loss: 0.8419930934906006\n",
      "Epoch: 4\t Train Loss: 305.33130687475204\t Validation Loss: 0.8222777247428894\n",
      "Epoch: 5\t Train Loss: 292.5341736674309\t Validation Loss: 0.8088980317115784\n",
      "Epoch: 6\t Train Loss: 285.0077056288719\t Validation Loss: 0.797065019607544\n",
      "Epoch: 7\t Train Loss: 277.813392162323\t Validation Loss: 0.8088728189468384\n",
      "Epoch: 8\t Train Loss: 275.1517615914345\t Validation Loss: 0.7904177904129028\n",
      "Epoch: 9\t Train Loss: 270.4338181614876\t Validation Loss: 0.8106430768966675\n",
      "Epoch: 10\t Train Loss: 265.6814925670624\t Validation Loss: 0.8255361914634705\n",
      "Epoch: 11\t Train Loss: 264.36902010440826\t Validation Loss: 0.8029248714447021\n",
      "Epoch: 12\t Train Loss: 259.7284687757492\t Validation Loss: 0.8251733779907227\n",
      "Epoch: 13\t Train Loss: 255.7080461382866\t Validation Loss: 0.7930094599723816\n",
      "Epoch: 14\t Train Loss: 254.05428314208984\t Validation Loss: 0.7918294668197632\n",
      "Epoch: 15\t Train Loss: 253.14099311828613\t Validation Loss: 0.7908250689506531\n",
      "Epoch: 16\t Train Loss: 253.59208130836487\t Validation Loss: 0.834954559803009\n",
      "Epoch: 17\t Train Loss: 252.02532613277435\t Validation Loss: 0.7952154278755188\n",
      "Epoch: 18\t Train Loss: 254.41585367918015\t Validation Loss: 0.802573561668396\n",
      "Epoch: 19\t Train Loss: 248.24073243141174\t Validation Loss: 0.7880575656890869\n",
      "Epoch: 20\t Train Loss: 246.58749854564667\t Validation Loss: 0.790360152721405\n",
      "Epoch: 21\t Train Loss: 245.95970249176025\t Validation Loss: 0.8006202578544617\n",
      "Epoch: 22\t Train Loss: 248.10761922597885\t Validation Loss: 0.7752535343170166\n",
      "Epoch: 23\t Train Loss: 246.27735829353333\t Validation Loss: 0.7830489277839661\n",
      "Epoch: 24\t Train Loss: 243.3418049812317\t Validation Loss: 0.7981067895889282\n",
      "Epoch: 25\t Train Loss: 242.2541339993477\t Validation Loss: 0.8070511817932129\n",
      "Epoch: 26\t Train Loss: 241.42579007148743\t Validation Loss: 0.8242860436439514\n",
      "Epoch: 27\t Train Loss: 240.2170776128769\t Validation Loss: 0.8071450591087341\n",
      "Epoch: 28\t Train Loss: 240.1833050251007\t Validation Loss: 0.8006089329719543\n",
      "Epoch: 29\t Train Loss: 238.2031232714653\t Validation Loss: 0.8138483166694641\n",
      "Epoch: 30\t Train Loss: 239.14243572950363\t Validation Loss: 0.8054018020629883\n",
      "Epoch: 31\t Train Loss: 237.96149915456772\t Validation Loss: 0.7970807552337646\n",
      "Epoch: 32\t Train Loss: 247.8180034160614\t Validation Loss: 0.8075389266014099\n",
      "Epoch: 33\t Train Loss: 238.49901509284973\t Validation Loss: 0.8054758310317993\n",
      "Epoch: 34\t Train Loss: 236.62130445241928\t Validation Loss: 0.8055235147476196\n",
      "Epoch: 35\t Train Loss: 236.07179081439972\t Validation Loss: 0.8308508992195129\n",
      "Epoch: 36\t Train Loss: 237.62020987272263\t Validation Loss: 0.832198977470398\n",
      "Epoch: 37\t Train Loss: 236.94160330295563\t Validation Loss: 0.7904873490333557\n",
      "Epoch: 38\t Train Loss: 235.0539237856865\t Validation Loss: 0.8005163073539734\n",
      "Epoch: 39\t Train Loss: 234.1704985499382\t Validation Loss: 0.7819381952285767\n",
      "Epoch: 40\t Train Loss: 233.41916674375534\t Validation Loss: 0.7828765511512756\n",
      "Epoch: 41\t Train Loss: 233.69896531105042\t Validation Loss: 0.8054673075675964\n",
      "Epoch: 42\t Train Loss: 239.44141119718552\t Validation Loss: 0.829784631729126\n",
      "Epoch: 43\t Train Loss: 236.43757957220078\t Validation Loss: 0.7968928217887878\n",
      "Epoch: 44\t Train Loss: 237.74751645326614\t Validation Loss: 0.7792177200317383\n",
      "Epoch: 45\t Train Loss: 232.85971122980118\t Validation Loss: 0.7847358584403992\n",
      "Epoch: 46\t Train Loss: 234.1122636795044\t Validation Loss: 0.794162929058075\n",
      "Epoch: 47\t Train Loss: 231.05774956941605\t Validation Loss: 0.7975625395774841\n",
      "Epoch: 48\t Train Loss: 230.58750718832016\t Validation Loss: 0.7990195751190186\n",
      "Epoch: 49\t Train Loss: 230.30440217256546\t Validation Loss: 0.7955327033996582\n",
      "Epoch: 50\t Train Loss: 230.2562579512596\t Validation Loss: 0.814182460308075\n",
      "Epoch: 51\t Train Loss: 229.83943784236908\t Validation Loss: 0.7880216836929321\n",
      "Epoch: 52\t Train Loss: 229.2602777481079\t Validation Loss: 0.8181267380714417\n",
      "Epoch: 53\t Train Loss: 232.2431579232216\t Validation Loss: 0.7866966724395752\n",
      "Epoch: 54\t Train Loss: 229.18046218156815\t Validation Loss: 0.7997052669525146\n",
      "Epoch: 55\t Train Loss: 229.0530840754509\t Validation Loss: 0.7960265874862671\n",
      "Epoch: 56\t Train Loss: 228.39269238710403\t Validation Loss: 0.8170063495635986\n",
      "Epoch: 57\t Train Loss: 228.56627422571182\t Validation Loss: 0.8237706422805786\n",
      "Epoch: 58\t Train Loss: 229.03491497039795\t Validation Loss: 0.8213511109352112\n",
      "Epoch: 59\t Train Loss: 228.5128270983696\t Validation Loss: 0.8136895298957825\n",
      "Epoch: 60\t Train Loss: 227.64265877008438\t Validation Loss: 0.8091676831245422\n",
      "Epoch: 61\t Train Loss: 227.08646249771118\t Validation Loss: 0.8005218505859375\n",
      "Epoch: 62\t Train Loss: 227.67536795139313\t Validation Loss: 0.8216497898101807\n",
      "Epoch: 63\t Train Loss: 235.92908960580826\t Validation Loss: 0.8034045696258545\n",
      "Epoch: 64\t Train Loss: 231.25669240951538\t Validation Loss: 0.8026375770568848\n",
      "Epoch: 65\t Train Loss: 229.18057143688202\t Validation Loss: 0.8190101981163025\n",
      "Epoch: 66\t Train Loss: 228.00995725393295\t Validation Loss: 0.8117016553878784\n",
      "Epoch: 67\t Train Loss: 227.09545809030533\t Validation Loss: 0.8033984899520874\n",
      "Epoch: 68\t Train Loss: 227.54514133930206\t Validation Loss: 0.8164545297622681\n",
      "Epoch: 69\t Train Loss: 228.89728993177414\t Validation Loss: 0.8081358671188354\n",
      "Epoch: 70\t Train Loss: 232.4875420331955\t Validation Loss: 0.836341917514801\n",
      "Epoch: 71\t Train Loss: 229.75873517990112\t Validation Loss: 0.7967610359191895\n",
      "Epoch: 72\t Train Loss: 227.2909750342369\t Validation Loss: 0.799851655960083\n",
      "Epoch: 73\t Train Loss: 226.71326333284378\t Validation Loss: 0.8131982088088989\n",
      "Epoch: 74\t Train Loss: 226.6246835589409\t Validation Loss: 0.7831091284751892\n",
      "Epoch: 75\t Train Loss: 226.05106222629547\t Validation Loss: 0.8136321902275085\n",
      "Epoch: 76\t Train Loss: 226.08979189395905\t Validation Loss: 0.8048967719078064\n",
      "Epoch: 77\t Train Loss: 228.10617792606354\t Validation Loss: 0.8063923716545105\n",
      "Epoch: 78\t Train Loss: 226.52611416578293\t Validation Loss: 0.8111141324043274\n",
      "Epoch: 79\t Train Loss: 225.54715329408646\t Validation Loss: 0.8116490244865417\n",
      "Epoch: 80\t Train Loss: 225.34177941083908\t Validation Loss: 0.8051658868789673\n",
      "Epoch: 81\t Train Loss: 225.32294976711273\t Validation Loss: 0.8006010055541992\n",
      "Epoch: 82\t Train Loss: 225.12035036087036\t Validation Loss: 0.7970008850097656\n",
      "Epoch: 83\t Train Loss: 225.17666566371918\t Validation Loss: 0.7864771485328674\n",
      "Epoch: 84\t Train Loss: 226.45479941368103\t Validation Loss: 0.8095968961715698\n",
      "Epoch: 85\t Train Loss: 225.64443093538284\t Validation Loss: 0.8156941533088684\n",
      "Epoch: 86\t Train Loss: 226.06141269207\t Validation Loss: 0.8217162489891052\n",
      "Epoch: 87\t Train Loss: 225.07870262861252\t Validation Loss: 0.8219088315963745\n",
      "Epoch: 88\t Train Loss: 224.73493283987045\t Validation Loss: 0.8100979924201965\n",
      "Epoch: 89\t Train Loss: 225.16869843006134\t Validation Loss: 0.7986574769020081\n",
      "Epoch: 90\t Train Loss: 224.70012563467026\t Validation Loss: 0.799065113067627\n",
      "Epoch: 91\t Train Loss: 224.99363619089127\t Validation Loss: 0.817501425743103\n",
      "Epoch: 92\t Train Loss: 224.64687448740005\t Validation Loss: 0.8068609237670898\n",
      "Epoch: 93\t Train Loss: 224.5258058309555\t Validation Loss: 0.8120908737182617\n",
      "Epoch: 94\t Train Loss: 224.3177947998047\t Validation Loss: 0.7985659837722778\n",
      "Epoch: 95\t Train Loss: 227.9949678182602\t Validation Loss: 0.8449921607971191\n",
      "Epoch: 96\t Train Loss: 228.4404981136322\t Validation Loss: 0.7703378200531006\n",
      "Epoch: 97\t Train Loss: 226.5933489203453\t Validation Loss: 0.7932525277137756\n",
      "Epoch: 98\t Train Loss: 224.2804548740387\t Validation Loss: 0.802229642868042\n",
      "Epoch: 99\t Train Loss: 226.94735383987427\t Validation Loss: 0.7765025496482849\n",
      "Epoch: 100\t Train Loss: 224.76253724098206\t Validation Loss: 0.8121731281280518\n",
      "Epoch: 101\t Train Loss: 224.29569160938263\t Validation Loss: 0.8019393086433411\n",
      "Epoch: 102\t Train Loss: 223.9291069507599\t Validation Loss: 0.7941940426826477\n",
      "Epoch: 103\t Train Loss: 224.08170300722122\t Validation Loss: 0.7951578497886658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104\t Train Loss: 223.86141765117645\t Validation Loss: 0.8065392971038818\n",
      "Epoch: 105\t Train Loss: 223.95570141077042\t Validation Loss: 0.806482195854187\n",
      "Epoch: 106\t Train Loss: 223.78172707557678\t Validation Loss: 0.8136574625968933\n",
      "Epoch: 107\t Train Loss: 226.48052644729614\t Validation Loss: 0.7774620652198792\n",
      "Epoch: 108\t Train Loss: 227.72796016931534\t Validation Loss: 0.7922357320785522\n",
      "Epoch: 109\t Train Loss: 226.66149580478668\t Validation Loss: 0.7961627840995789\n",
      "Epoch: 110\t Train Loss: 223.86974161863327\t Validation Loss: 0.8063536882400513\n",
      "Epoch: 111\t Train Loss: 223.7767617702484\t Validation Loss: 0.8127657771110535\n",
      "Epoch: 112\t Train Loss: 223.15650880336761\t Validation Loss: 0.8161711692810059\n",
      "Epoch: 113\t Train Loss: 224.04628014564514\t Validation Loss: 0.8045825362205505\n",
      "Epoch: 114\t Train Loss: 223.1669016480446\t Validation Loss: 0.7988268733024597\n",
      "Epoch: 115\t Train Loss: 223.3756331205368\t Validation Loss: 0.8016646504402161\n",
      "Epoch: 116\t Train Loss: 223.33297777175903\t Validation Loss: 0.796944260597229\n",
      "Epoch: 117\t Train Loss: 222.83386051654816\t Validation Loss: 0.8153809905052185\n",
      "Epoch: 118\t Train Loss: 222.81542015075684\t Validation Loss: 0.8183590173721313\n",
      "Epoch: 119\t Train Loss: 222.63241463899612\t Validation Loss: 0.8163995146751404\n",
      "Epoch: 120\t Train Loss: 222.58311867713928\t Validation Loss: 0.8148118257522583\n",
      "Epoch: 121\t Train Loss: 222.73635309934616\t Validation Loss: 0.8215619325637817\n",
      "Epoch: 122\t Train Loss: 222.63436049222946\t Validation Loss: 0.8185028433799744\n",
      "Epoch: 123\t Train Loss: 222.93661147356033\t Validation Loss: 0.8103943467140198\n",
      "Epoch: 124\t Train Loss: 222.6634840965271\t Validation Loss: 0.8092377781867981\n",
      "Epoch: 125\t Train Loss: 223.88234013319016\t Validation Loss: 0.8015981316566467\n",
      "Epoch: 126\t Train Loss: 223.69998854398727\t Validation Loss: 0.7855717539787292\n",
      "Epoch: 127\t Train Loss: 222.97399055957794\t Validation Loss: 0.789742112159729\n",
      "Epoch: 128\t Train Loss: 222.50379484891891\t Validation Loss: 0.817478358745575\n",
      "Epoch: 129\t Train Loss: 224.30106157064438\t Validation Loss: 0.769374430179596\n",
      "Epoch: 130\t Train Loss: 223.9425891637802\t Validation Loss: 0.7857111692428589\n",
      "Epoch: 131\t Train Loss: 223.49342840909958\t Validation Loss: 0.8084204792976379\n",
      "Epoch: 132\t Train Loss: 227.45917564630508\t Validation Loss: 0.7845287919044495\n",
      "Epoch: 133\t Train Loss: 225.40588384866714\t Validation Loss: 0.818348228931427\n",
      "Epoch: 134\t Train Loss: 223.24045550823212\t Validation Loss: 0.7876859307289124\n",
      "Epoch: 135\t Train Loss: 222.7373034954071\t Validation Loss: 0.7988516688346863\n",
      "Epoch: 136\t Train Loss: 222.36416137218475\t Validation Loss: 0.7893567681312561\n",
      "Epoch: 137\t Train Loss: 222.8103044629097\t Validation Loss: 0.7867529392242432\n",
      "Epoch: 138\t Train Loss: 222.28203105926514\t Validation Loss: 0.8006313443183899\n",
      "Epoch: 139\t Train Loss: 222.20655155181885\t Validation Loss: 0.794782280921936\n",
      "Epoch: 140\t Train Loss: 222.15960788726807\t Validation Loss: 0.8148137927055359\n",
      "Epoch: 141\t Train Loss: 222.08452659845352\t Validation Loss: 0.790237545967102\n",
      "Epoch: 142\t Train Loss: 222.29503458738327\t Validation Loss: 0.7926661372184753\n",
      "Epoch: 143\t Train Loss: 222.1216877102852\t Validation Loss: 0.7927776575088501\n",
      "Epoch: 144\t Train Loss: 222.1632118821144\t Validation Loss: 0.8018943071365356\n",
      "Epoch: 145\t Train Loss: 222.13896363973618\t Validation Loss: 0.7880966663360596\n",
      "Epoch: 146\t Train Loss: 222.01270759105682\t Validation Loss: 0.7945933938026428\n",
      "Epoch: 147\t Train Loss: 221.8869355916977\t Validation Loss: 0.7895715236663818\n",
      "Epoch: 148\t Train Loss: 221.86209619045258\t Validation Loss: 0.7892937660217285\n",
      "Epoch: 149\t Train Loss: 222.02919727563858\t Validation Loss: 0.7884153127670288\n",
      "Epoch: 150\t Train Loss: 222.11160868406296\t Validation Loss: 0.7790175080299377\n",
      "Epoch: 151\t Train Loss: 225.71339464187622\t Validation Loss: 0.8021437525749207\n",
      "Epoch: 152\t Train Loss: 224.70778834819794\t Validation Loss: 0.7992852926254272\n",
      "Epoch: 153\t Train Loss: 226.04020124673843\t Validation Loss: 0.7975849509239197\n",
      "Epoch: 154\t Train Loss: 222.6030102968216\t Validation Loss: 0.7980937957763672\n",
      "Epoch: 155\t Train Loss: 222.29050755500793\t Validation Loss: 0.7999759316444397\n",
      "Epoch: 156\t Train Loss: 222.554933488369\t Validation Loss: 0.7835864424705505\n",
      "Epoch: 157\t Train Loss: 222.6860693693161\t Validation Loss: 0.7858543992042542\n",
      "Epoch: 158\t Train Loss: 221.90414375066757\t Validation Loss: 0.7842978239059448\n",
      "Epoch: 159\t Train Loss: 221.81768292188644\t Validation Loss: 0.7939812541007996\n",
      "Epoch: 160\t Train Loss: 221.8025477528572\t Validation Loss: 0.7866226434707642\n",
      "Epoch: 161\t Train Loss: 221.80828696489334\t Validation Loss: 0.7967990636825562\n",
      "Epoch: 162\t Train Loss: 221.93346172571182\t Validation Loss: 0.8176097869873047\n",
      "Epoch: 163\t Train Loss: 221.60104250907898\t Validation Loss: 0.789372980594635\n",
      "Epoch: 164\t Train Loss: 222.31351429224014\t Validation Loss: 0.7927161455154419\n",
      "Epoch: 165\t Train Loss: 223.6662946343422\t Validation Loss: 0.8094313740730286\n",
      "Epoch: 166\t Train Loss: 222.19559133052826\t Validation Loss: 0.8135626316070557\n",
      "Epoch: 167\t Train Loss: 221.70917558670044\t Validation Loss: 0.8144763112068176\n",
      "Epoch: 168\t Train Loss: 222.06109875440598\t Validation Loss: 0.823298990726471\n",
      "Epoch: 169\t Train Loss: 222.00920498371124\t Validation Loss: 0.7991618514060974\n",
      "Epoch: 170\t Train Loss: 221.64343911409378\t Validation Loss: 0.8290102481842041\n",
      "Epoch: 171\t Train Loss: 221.83510994911194\t Validation Loss: 0.8042788505554199\n",
      "Epoch: 172\t Train Loss: 221.57114589214325\t Validation Loss: 0.7840719223022461\n",
      "Epoch: 173\t Train Loss: 221.57637977600098\t Validation Loss: 0.7868606448173523\n",
      "Epoch: 174\t Train Loss: 221.87696760892868\t Validation Loss: 0.7933461666107178\n",
      "Epoch: 175\t Train Loss: 221.92434722185135\t Validation Loss: 0.7915834188461304\n",
      "Epoch: 176\t Train Loss: 222.35067057609558\t Validation Loss: 0.8154202103614807\n",
      "Epoch: 177\t Train Loss: 221.63153332471848\t Validation Loss: 0.7925304174423218\n",
      "Epoch: 178\t Train Loss: 221.44493114948273\t Validation Loss: 0.7880284190177917\n",
      "Epoch: 179\t Train Loss: 221.49658566713333\t Validation Loss: 0.7930421829223633\n",
      "Epoch: 180\t Train Loss: 221.45457243919373\t Validation Loss: 0.8116557002067566\n",
      "Epoch: 181\t Train Loss: 221.4631623029709\t Validation Loss: 0.800462007522583\n",
      "Epoch: 182\t Train Loss: 221.27330285310745\t Validation Loss: 0.8202676773071289\n",
      "Epoch: 183\t Train Loss: 223.54655116796494\t Validation Loss: 0.8276262283325195\n",
      "Epoch: 184\t Train Loss: 232.38210064172745\t Validation Loss: 0.7949833869934082\n",
      "Epoch: 185\t Train Loss: 223.0314506292343\t Validation Loss: 0.7938297390937805\n",
      "Epoch: 186\t Train Loss: 222.18419480323792\t Validation Loss: 0.7806150317192078\n",
      "Epoch: 187\t Train Loss: 221.76308727264404\t Validation Loss: 0.7932379841804504\n",
      "Epoch: 188\t Train Loss: 221.41829895973206\t Validation Loss: 0.7894899845123291\n",
      "Epoch: 189\t Train Loss: 221.31167900562286\t Validation Loss: 0.8004372715950012\n",
      "Epoch: 190\t Train Loss: 221.2531437277794\t Validation Loss: 0.8011516332626343\n",
      "Epoch: 191\t Train Loss: 221.23123043775558\t Validation Loss: 0.7904669642448425\n",
      "Epoch: 192\t Train Loss: 221.22380483150482\t Validation Loss: 0.7993167042732239\n",
      "Epoch: 193\t Train Loss: 221.39205694198608\t Validation Loss: 0.7895640730857849\n",
      "Epoch: 194\t Train Loss: 221.52643185853958\t Validation Loss: 0.7934860587120056\n",
      "Epoch: 195\t Train Loss: 221.15536612272263\t Validation Loss: 0.7881727814674377\n",
      "Epoch: 196\t Train Loss: 221.12639737129211\t Validation Loss: 0.7889584302902222\n",
      "Epoch: 197\t Train Loss: 221.75826108455658\t Validation Loss: 0.811383843421936\n",
      "Epoch: 198\t Train Loss: 223.43458288908005\t Validation Loss: 0.788079559803009\n",
      "Epoch: 199\t Train Loss: 223.02712386846542\t Validation Loss: 0.7585034370422363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<elmo_on_md.evaluation.sentiment_analysis.SentimentAnalysis at 0x1aca02967b8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "elmo = load_model('original')\n",
    "sentiment = SentimentAnalysis(elmo,lr=1e-4)\n",
    "sentences = sentiment_data['train']['sentences']\n",
    "labels = sentiment_data['train']['labels']\n",
    "\n",
    "tokens_train,tokens_test, labels_train,labels_test = train_test_split(sentences, labels, test_size=0.2, random_state=1)\n",
    "\n",
    "train_set = {'sentences':tokens_train,'labels':labels_train}\n",
    "validate_set = {'sentences':tokens_test,'labels':labels_test}\n",
    "\n",
    "sentiment.train(train_set,validate_set,n_epochs=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0826 00:16:09.515891 16988 elmo.py:97] 161 batches, avg len: 17.0\n",
      "I0826 00:17:18.708282 16988 elmo.py:211] Finished 1000 sentences.\n",
      "I0826 00:18:09.752365 16988 elmo.py:211] Finished 2000 sentences.\n",
      "I0826 00:19:11.690146 16988 elmo.py:211] Finished 3000 sentences.\n",
      "I0826 00:20:04.656741 16988 elmo.py:211] Finished 4000 sentences.\n",
      "I0826 00:21:08.080207 16988 elmo.py:211] Finished 5000 sentences.\n",
      "I0826 00:22:00.888988 16988 elmo.py:211] Finished 6000 sentences.\n",
      "I0826 00:22:59.192112 16988 elmo.py:211] Finished 7000 sentences.\n",
      "I0826 00:23:49.285412 16988 elmo.py:211] Finished 8000 sentences.\n",
      "I0826 00:24:28.830652 16988 elmo.py:211] Finished 9000 sentences.\n",
      "I0826 00:25:37.947032 16988 elmo.py:211] Finished 10000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6336  357  121]\n",
      " [ 223 2841   68]\n",
      " [  18   14  266]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0826 00:26:17.425742 16988 elmo.py:97] 40 batches, avg len: 17.1\n",
      "I0826 00:27:16.036770 16988 elmo.py:211] Finished 1000 sentences.\n",
      "I0826 00:28:21.057963 16988 elmo.py:211] Finished 2000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1521  144   33]\n",
      " [  98  658   34]\n",
      " [  16   20   36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.96      0.93      0.95      6814\n",
      "     neutral       0.88      0.91      0.90      3132\n",
      "        good       0.58      0.89      0.71       298\n",
      "\n",
      "    accuracy                           0.92     10244\n",
      "   macro avg       0.81      0.91      0.85     10244\n",
      "weighted avg       0.93      0.92      0.92     10244\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.93      0.90      0.91      1698\n",
      "     neutral       0.80      0.83      0.82       790\n",
      "        good       0.35      0.50      0.41        72\n",
      "\n",
      "    accuracy                           0.87      2560\n",
      "   macro avg       0.69      0.74      0.71      2560\n",
      "weighted avg       0.87      0.87      0.87      2560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_preds = sentiment.predict(sentiment_data['train'])\n",
    "print(confusion_matrix(sentiment_data['train']['labels'],train_preds))\n",
    "test_preds = sentiment.predict(sentiment_data['test'])\n",
    "print(confusion_matrix(sentiment_data['test']['labels'],test_preds))\n",
    "from sklearn.metrics import precision_recall_fscore_support,classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support,classification_report\n",
    "print(classification_report(sentiment_data['train']['labels'],train_preds,target_names=['bad','neutral','good']))\n",
    "print(classification_report(sentiment_data['test']['labels'],test_preds,target_names=['bad','neutral','good']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0824 12:49:25.633167 21040 elmo.py:97] 161 batches, avg len: 17.0\n",
      "I0824 12:50:33.290285 21040 elmo.py:211] Finished 1000 sentences.\n",
      "I0824 12:51:23.120063 21040 elmo.py:211] Finished 2000 sentences.\n",
      "I0824 12:52:18.743351 21040 elmo.py:211] Finished 3000 sentences.\n",
      "I0824 12:53:30.671048 21040 elmo.py:211] Finished 4000 sentences.\n",
      "I0824 12:54:28.752764 21040 elmo.py:211] Finished 5000 sentences.\n",
      "I0824 12:55:16.594856 21040 elmo.py:211] Finished 6000 sentences.\n",
      "I0824 12:56:22.606369 21040 elmo.py:211] Finished 7000 sentences.\n",
      "I0824 12:57:20.747925 21040 elmo.py:211] Finished 8000 sentences.\n",
      "I0824 12:58:08.270870 21040 elmo.py:211] Finished 9000 sentences.\n",
      "I0824 12:58:56.832039 21040 elmo.py:211] Finished 10000 sentences.\n",
      "..\\elmo_on_md\\evaluation\\sentiment_analysis.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5886  872   56]\n",
      " [ 182 2918   32]\n",
      " [  15   45  238]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0824 12:59:34.101390 21040 elmo.py:97] 40 batches, avg len: 17.1\n",
      "I0824 13:00:28.782982 21040 elmo.py:211] Finished 1000 sentences.\n",
      "I0824 13:01:30.980684 21040 elmo.py:211] Finished 2000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1389  287   22]\n",
      " [  75  703   12]\n",
      " [  11   32   29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.97      0.86      0.91      6814\n",
      "     neutral       0.76      0.93      0.84      3132\n",
      "        good       0.73      0.80      0.76       298\n",
      "\n",
      "    accuracy                           0.88     10244\n",
      "   macro avg       0.82      0.86      0.84     10244\n",
      "weighted avg       0.90      0.88      0.89     10244\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.94      0.82      0.88      1698\n",
      "     neutral       0.69      0.89      0.78       790\n",
      "        good       0.46      0.40      0.43        72\n",
      "\n",
      "    accuracy                           0.83      2560\n",
      "   macro avg       0.70      0.70      0.69      2560\n",
      "weighted avg       0.85      0.83      0.83      2560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_preds = sentiment.predict(sentiment_data['train'])\n",
    "print(confusion_matrix(sentiment_data['train']['labels'],train_preds))\n",
    "test_preds = sentiment.predict(sentiment_data['test'])\n",
    "print(confusion_matrix(sentiment_data['test']['labels'],test_preds))\n",
    "from sklearn.metrics import precision_recall_fscore_support,classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support,classification_report\n",
    "print(classification_report(sentiment_data['train']['labels'],train_preds,target_names=['bad','neutral','good']))\n",
    "print(classification_report(sentiment_data['test']['labels'],test_preds,target_names=['bad','neutral','good']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentiment_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-61034dad15c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentiment_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_preds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bad'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'neutral'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'good'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sentiment_data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,classification_report\n",
    "print(classification_report(sentiment_data['train']['labels'],train_preds,target_names=['bad','neutral','good']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,classification_report\n",
    "print(classification_report(sentiment_data['test']['labels'],test_preds,target_names=['bad','neutral','good']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.train(train_set,validate_set,n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = sentiment.predict(sentiment_data['train'])\n",
    "print(confusion_matrix(sentiment_data['train']['labels'],train_preds))\n",
    "test_preds = sentiment.predict(sentiment_data['test'])\n",
    "print(confusion_matrix(sentiment_data['test']['labels'],test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.summary.event_accumulator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6bb50b406296>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevent_accumulator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEventAccumulator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.summary.event_accumulator'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.python.summary.event_accumulator import EventAccumulator\n",
    "\n",
    "\n",
    "log_file = \"D://Projects/events.out.tfevents.1566034114.DESKTOP-OE11P6R.5500.0\"\n",
    "plot_tensorflow_log(log_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
