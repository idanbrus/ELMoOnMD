{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:41:54.587303Z",
     "start_time": "2019-08-30T08:41:53.124867Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('../')\n",
    "\n",
    "from typing import List,Dict\n",
    "from elmo_on_md.data_loaders.sentiment_loader import SentimentLoader\n",
    "from elmo_on_md.evaluation.sentiment_analysis import SentimentAnalysis\n",
    "from elmo_on_md.evaluation.model_loader import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:41:55.769797Z",
     "start_time": "2019-08-30T08:41:54.588304Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = SentimentLoader()\n",
    "sentiment_data = loader.load_data()\n",
    "\n",
    "sentences = sentiment_data['train']['sentences']\n",
    "labels = sentiment_data['train']['labels']\n",
    "\n",
    "tokens_train,tokens_test, labels_train,labels_test = train_test_split(sentences, labels, test_size=0.2, random_state=1)\n",
    "train_set = {'sentences':tokens_train,'labels':labels_train}\n",
    "validate_set = {'sentences':tokens_test,'labels':labels_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:41:04.661452Z",
     "start_time": "2019-08-30T08:33:54.790957Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-30 11:33:54,842 INFO: char embedding size: 2289\n",
      "2019-08-30 11:33:55,544 INFO: word embedding size: 189561\n",
      "2019-08-30 11:34:00,310 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(189561, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(2289, 50, padding_idx=2286)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2019-08-30 11:34:16,701 INFO: 257 batches, avg len: 16.9\n",
      "2019-08-30 11:34:20,434 INFO: Finished 1000 sentences.\n",
      "2019-08-30 11:34:24,197 INFO: Finished 2000 sentences.\n",
      "2019-08-30 11:34:27,987 INFO: Finished 3000 sentences.\n",
      "2019-08-30 11:34:31,811 INFO: Finished 4000 sentences.\n",
      "2019-08-30 11:34:35,040 INFO: Finished 5000 sentences.\n",
      "2019-08-30 11:34:39,304 INFO: Finished 6000 sentences.\n",
      "2019-08-30 11:34:42,770 INFO: Finished 7000 sentences.\n",
      "2019-08-30 11:34:46,730 INFO: Finished 8000 sentences.\n",
      "2019-08-30 11:34:51,379 INFO: 65 batches, avg len: 17.2\n",
      "2019-08-30 11:34:55,024 INFO: Finished 1000 sentences.\n",
      "2019-08-30 11:34:59,088 INFO: Finished 2000 sentences.\n",
      "..\\elmo_on_md\\evaluation\\sentiment_analysis.py:65: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.softmax(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\t Train Loss: 1.251713752746582\t Validation Loss: 0.9798790216445923\n",
      "Epoch: 1\t Train Loss: 1.238234043121338\t Validation Loss: 0.8694154620170593\n",
      "Epoch: 2\t Train Loss: 1.1014785766601562\t Validation Loss: 0.8371168375015259\n",
      "Epoch: 3\t Train Loss: 0.7940273880958557\t Validation Loss: 0.8148648738861084\n",
      "Epoch: 4\t Train Loss: 0.627234697341919\t Validation Loss: 0.8098123669624329\n",
      "Epoch: 5\t Train Loss: 0.5830479860305786\t Validation Loss: 0.8079448342323303\n",
      "Epoch: 6\t Train Loss: 0.6025349497795105\t Validation Loss: 0.820486843585968\n",
      "Epoch: 7\t Train Loss: 0.5655662417411804\t Validation Loss: 0.809010922908783\n",
      "Epoch: 8\t Train Loss: 0.5696036219596863\t Validation Loss: 0.7868145704269409\n",
      "Epoch: 9\t Train Loss: 0.5614644885063171\t Validation Loss: 0.7845606207847595\n",
      "Epoch: 10\t Train Loss: 0.5696258544921875\t Validation Loss: 0.8034985065460205\n",
      "Epoch: 11\t Train Loss: 0.5669284462928772\t Validation Loss: 0.8192839622497559\n",
      "Epoch: 12\t Train Loss: 0.5548382997512817\t Validation Loss: 0.813048243522644\n",
      "Epoch: 13\t Train Loss: 0.557149350643158\t Validation Loss: 0.7804930806159973\n",
      "Epoch: 14\t Train Loss: 0.552344560623169\t Validation Loss: 0.7800089120864868\n",
      "Epoch: 15\t Train Loss: 0.5533748865127563\t Validation Loss: 0.7959895133972168\n",
      "Epoch: 16\t Train Loss: 0.5524911880493164\t Validation Loss: 0.7775903940200806\n",
      "Epoch: 17\t Train Loss: 0.5578987002372742\t Validation Loss: 0.7960807681083679\n",
      "Epoch: 18\t Train Loss: 0.5525011420249939\t Validation Loss: 0.7800875902175903\n",
      "Epoch: 19\t Train Loss: 0.5518340468406677\t Validation Loss: 0.7964702248573303\n",
      "Epoch: 20\t Train Loss: 0.553555965423584\t Validation Loss: 0.8042030334472656\n",
      "Epoch: 21\t Train Loss: 0.5534720420837402\t Validation Loss: 0.8024216890335083\n",
      "Epoch: 22\t Train Loss: 0.5539084672927856\t Validation Loss: 0.8014379143714905\n",
      "Epoch: 23\t Train Loss: 0.5523207783699036\t Validation Loss: 0.7898679971694946\n",
      "Epoch: 24\t Train Loss: 0.5540593862533569\t Validation Loss: 0.7990188598632812\n",
      "Epoch: 25\t Train Loss: 0.552727460861206\t Validation Loss: 0.8029967546463013\n",
      "Epoch: 26\t Train Loss: 0.5527082681655884\t Validation Loss: 0.799811601638794\n",
      "Epoch: 27\t Train Loss: 0.5519176125526428\t Validation Loss: 0.7892951965332031\n",
      "Epoch: 28\t Train Loss: 0.552081823348999\t Validation Loss: 0.8004992604255676\n",
      "Epoch: 29\t Train Loss: 0.5516599416732788\t Validation Loss: 0.7895007133483887\n",
      "Epoch: 30\t Train Loss: 0.5525875687599182\t Validation Loss: 0.8040301203727722\n",
      "Epoch: 31\t Train Loss: 0.5514891147613525\t Validation Loss: 0.7953553795814514\n",
      "Epoch: 32\t Train Loss: 0.5515877604484558\t Validation Loss: 0.8022960424423218\n",
      "Epoch: 33\t Train Loss: 0.5516777038574219\t Validation Loss: 0.8039050102233887\n",
      "Epoch: 34\t Train Loss: 0.5527029037475586\t Validation Loss: 0.7891759276390076\n",
      "Epoch: 35\t Train Loss: 0.5517762303352356\t Validation Loss: 0.8316783308982849\n",
      "Epoch: 36\t Train Loss: 0.5516766309738159\t Validation Loss: 0.7943885326385498\n",
      "Epoch: 37\t Train Loss: 0.5515555143356323\t Validation Loss: 0.7747127413749695\n",
      "Epoch: 38\t Train Loss: 0.5515123605728149\t Validation Loss: 0.798395574092865\n",
      "Epoch: 39\t Train Loss: 0.5515943765640259\t Validation Loss: 0.7858940958976746\n",
      "Epoch: 40\t Train Loss: 0.5527885556221008\t Validation Loss: 0.791541576385498\n",
      "Epoch: 41\t Train Loss: 0.5514923334121704\t Validation Loss: 0.7845651507377625\n",
      "Epoch: 42\t Train Loss: 0.5515251159667969\t Validation Loss: 0.7895460724830627\n",
      "Epoch: 43\t Train Loss: 0.5514903664588928\t Validation Loss: 0.7857149243354797\n",
      "Epoch: 44\t Train Loss: 0.5514969825744629\t Validation Loss: 0.7893323302268982\n",
      "Epoch: 45\t Train Loss: 0.5521552562713623\t Validation Loss: 0.7942671775817871\n",
      "Epoch: 46\t Train Loss: 0.5515477657318115\t Validation Loss: 0.7858611941337585\n",
      "Epoch: 47\t Train Loss: 0.551518976688385\t Validation Loss: 0.7901826500892639\n",
      "Epoch: 48\t Train Loss: 0.5519548058509827\t Validation Loss: 0.7899198532104492\n",
      "Epoch: 49\t Train Loss: 0.5515163540840149\t Validation Loss: 0.8016740083694458\n",
      "Epoch: 50\t Train Loss: 0.551459789276123\t Validation Loss: 0.7866438031196594\n",
      "Epoch: 51\t Train Loss: 0.5515219569206238\t Validation Loss: 0.7979947924613953\n",
      "Epoch: 52\t Train Loss: 0.5515220165252686\t Validation Loss: 0.8112549185752869\n",
      "Epoch: 53\t Train Loss: 0.551480233669281\t Validation Loss: 0.8032782673835754\n",
      "Epoch: 54\t Train Loss: 0.5515474677085876\t Validation Loss: 0.7899671196937561\n",
      "Epoch: 55\t Train Loss: 0.5514559745788574\t Validation Loss: 0.7971941828727722\n",
      "Epoch: 56\t Train Loss: 0.5517165660858154\t Validation Loss: 0.802839457988739\n",
      "Epoch: 57\t Train Loss: 0.5514721274375916\t Validation Loss: 0.8101470470428467\n",
      "Epoch: 58\t Train Loss: 0.5514471530914307\t Validation Loss: 0.7968043088912964\n",
      "Epoch: 59\t Train Loss: 0.5514614582061768\t Validation Loss: 0.7944746613502502\n",
      "Epoch: 60\t Train Loss: 0.551499605178833\t Validation Loss: 0.8022128939628601\n",
      "Epoch: 61\t Train Loss: 0.5514549016952515\t Validation Loss: 0.7966587543487549\n",
      "Epoch: 62\t Train Loss: 0.5514937043190002\t Validation Loss: 0.8162404298782349\n",
      "Epoch: 63\t Train Loss: 0.5515946745872498\t Validation Loss: 0.7615423202514648\n",
      "Epoch: 64\t Train Loss: 0.5515721440315247\t Validation Loss: 0.7953671813011169\n",
      "Epoch: 65\t Train Loss: 0.5514916181564331\t Validation Loss: 0.7818527817726135\n",
      "Epoch: 66\t Train Loss: 0.5514637231826782\t Validation Loss: 0.7817792892456055\n",
      "Epoch: 67\t Train Loss: 0.5514623522758484\t Validation Loss: 0.7804491519927979\n",
      "Epoch: 68\t Train Loss: 0.5514804124832153\t Validation Loss: 0.7876811623573303\n",
      "Epoch: 69\t Train Loss: 0.5515209436416626\t Validation Loss: 0.791741669178009\n",
      "Epoch: 70\t Train Loss: 0.5514581799507141\t Validation Loss: 0.7851495742797852\n",
      "Epoch: 71\t Train Loss: 0.5515022873878479\t Validation Loss: 0.7853315472602844\n",
      "Epoch: 72\t Train Loss: 0.5514646768569946\t Validation Loss: 0.7990553975105286\n",
      "Epoch: 73\t Train Loss: 0.5514611005783081\t Validation Loss: 0.787224292755127\n",
      "Epoch: 74\t Train Loss: 0.5514882206916809\t Validation Loss: 0.7855658531188965\n",
      "Epoch: 75\t Train Loss: 0.5515842437744141\t Validation Loss: 0.8260682225227356\n",
      "Epoch: 76\t Train Loss: 0.5515078902244568\t Validation Loss: 0.7962146401405334\n",
      "Epoch: 77\t Train Loss: 0.5515004396438599\t Validation Loss: 0.7946865558624268\n",
      "Epoch: 78\t Train Loss: 0.5514553189277649\t Validation Loss: 0.8001278042793274\n",
      "Epoch: 79\t Train Loss: 0.5514623522758484\t Validation Loss: 0.7759749293327332\n",
      "Epoch: 80\t Train Loss: 0.5514531135559082\t Validation Loss: 0.7940663695335388\n",
      "Epoch: 81\t Train Loss: 0.5514643788337708\t Validation Loss: 0.8061962723731995\n",
      "Epoch: 82\t Train Loss: 0.5514525771141052\t Validation Loss: 0.7971377968788147\n",
      "Epoch: 83\t Train Loss: 0.5514559149742126\t Validation Loss: 0.8551499247550964\n",
      "Epoch: 84\t Train Loss: 0.5514469146728516\t Validation Loss: 0.7599484920501709\n",
      "Epoch: 85\t Train Loss: 0.5514666438102722\t Validation Loss: 0.800150990486145\n",
      "Epoch: 86\t Train Loss: 0.5514640808105469\t Validation Loss: 0.8090983033180237\n",
      "Epoch: 87\t Train Loss: 0.5515106916427612\t Validation Loss: 0.7998570203781128\n",
      "Epoch: 88\t Train Loss: 0.5514724254608154\t Validation Loss: 0.7942770719528198\n",
      "Epoch: 89\t Train Loss: 0.5520811080932617\t Validation Loss: 0.8060667514801025\n",
      "Epoch: 90\t Train Loss: 0.5514922738075256\t Validation Loss: 0.8155508041381836\n",
      "Epoch: 91\t Train Loss: 0.5514463186264038\t Validation Loss: 0.8123726844787598\n",
      "Epoch: 92\t Train Loss: 0.5514992475509644\t Validation Loss: 0.8047927021980286\n",
      "Epoch: 93\t Train Loss: 0.5514599084854126\t Validation Loss: 0.8044822216033936\n",
      "Epoch: 94\t Train Loss: 0.5514552593231201\t Validation Loss: 0.8085528016090393\n",
      "Epoch: 95\t Train Loss: 0.5514762997627258\t Validation Loss: 0.8002390265464783\n",
      "Epoch: 96\t Train Loss: 0.5514510869979858\t Validation Loss: 0.8095955848693848\n",
      "Epoch: 97\t Train Loss: 0.5514494180679321\t Validation Loss: 0.7834486961364746\n",
      "Epoch: 98\t Train Loss: 0.5514529347419739\t Validation Loss: 0.7967103123664856\n",
      "Epoch: 99\t Train Loss: 0.5514571666717529\t Validation Loss: 0.7935838103294373\n",
      "Epoch: 100\t Train Loss: 0.5514558553695679\t Validation Loss: 0.7869624495506287\n",
      "Epoch: 101\t Train Loss: 0.5514634251594543\t Validation Loss: 0.7812738418579102\n",
      "Epoch: 102\t Train Loss: 0.5514522194862366\t Validation Loss: 0.7873286008834839\n",
      "Epoch: 103\t Train Loss: 0.5514832139015198\t Validation Loss: 0.8015384674072266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104\t Train Loss: 0.5514719486236572\t Validation Loss: 0.7779171466827393\n",
      "Epoch: 105\t Train Loss: 0.5515329837799072\t Validation Loss: 0.7973482012748718\n",
      "Epoch: 106\t Train Loss: 0.551449716091156\t Validation Loss: 0.7974193692207336\n",
      "Epoch: 107\t Train Loss: 0.5514612793922424\t Validation Loss: 0.7956085205078125\n",
      "Epoch: 108\t Train Loss: 0.5514475107192993\t Validation Loss: 0.8092987537384033\n",
      "Epoch: 109\t Train Loss: 0.551445484161377\t Validation Loss: 0.8000390529632568\n",
      "Epoch: 110\t Train Loss: 0.5514453053474426\t Validation Loss: 0.8003888130187988\n",
      "Epoch: 111\t Train Loss: 0.5514583587646484\t Validation Loss: 0.7809305787086487\n",
      "Epoch: 112\t Train Loss: 0.5514459609985352\t Validation Loss: 0.7929240465164185\n",
      "Epoch: 113\t Train Loss: 0.5514534115791321\t Validation Loss: 0.8291666507720947\n",
      "Epoch: 114\t Train Loss: 0.5514469742774963\t Validation Loss: 0.8105924725532532\n",
      "Epoch: 115\t Train Loss: 0.5515406131744385\t Validation Loss: 0.7989011406898499\n",
      "Epoch: 116\t Train Loss: 0.5514614582061768\t Validation Loss: 0.7818027138710022\n",
      "Epoch: 117\t Train Loss: 0.5514453053474426\t Validation Loss: 0.7896429896354675\n",
      "Epoch: 118\t Train Loss: 0.5514523386955261\t Validation Loss: 0.7966359853744507\n",
      "Epoch: 119\t Train Loss: 0.5521562099456787\t Validation Loss: 0.8018664717674255\n",
      "Epoch: 120\t Train Loss: 0.551445484161377\t Validation Loss: 0.7861610651016235\n",
      "Epoch: 121\t Train Loss: 0.5514479875564575\t Validation Loss: 0.7949709296226501\n",
      "Epoch: 122\t Train Loss: 0.5514489412307739\t Validation Loss: 0.7905424237251282\n",
      "Epoch: 123\t Train Loss: 0.5514460802078247\t Validation Loss: 0.7897239327430725\n",
      "Epoch: 124\t Train Loss: 0.5514484643936157\t Validation Loss: 0.7818465232849121\n",
      "Epoch: 125\t Train Loss: 0.5514487028121948\t Validation Loss: 0.8011136054992676\n",
      "Epoch: 126\t Train Loss: 0.5514454245567322\t Validation Loss: 0.7955767512321472\n",
      "Epoch: 127\t Train Loss: 0.5514463186264038\t Validation Loss: 0.795469343662262\n",
      "Epoch: 128\t Train Loss: 0.5514458417892456\t Validation Loss: 0.7820786237716675\n",
      "Epoch: 129\t Train Loss: 0.551445484161377\t Validation Loss: 0.7834472060203552\n",
      "Epoch: 130\t Train Loss: 0.5514448285102844\t Validation Loss: 0.7931974530220032\n",
      "Epoch: 131\t Train Loss: 0.551444947719574\t Validation Loss: 0.7959750294685364\n",
      "Epoch: 132\t Train Loss: 0.5514535307884216\t Validation Loss: 0.7957333922386169\n",
      "Epoch: 133\t Train Loss: 0.5514463782310486\t Validation Loss: 0.8000070452690125\n",
      "Epoch: 134\t Train Loss: 0.5514494180679321\t Validation Loss: 0.813889741897583\n",
      "Epoch: 135\t Train Loss: 0.5514651536941528\t Validation Loss: 0.7891401052474976\n",
      "Epoch: 136\t Train Loss: 0.5514524579048157\t Validation Loss: 0.8115728497505188\n",
      "Epoch: 137\t Train Loss: 0.5514487028121948\t Validation Loss: 0.7667399048805237\n",
      "Epoch: 138\t Train Loss: 0.5514516830444336\t Validation Loss: 0.7821849584579468\n",
      "Epoch: 139\t Train Loss: 0.5514451265335083\t Validation Loss: 0.7771819233894348\n",
      "Epoch: 140\t Train Loss: 0.5514611005783081\t Validation Loss: 0.7885028123855591\n",
      "Epoch: 141\t Train Loss: 0.5514578223228455\t Validation Loss: 0.7831340432167053\n",
      "Epoch: 142\t Train Loss: 0.5514601469039917\t Validation Loss: 0.7753334641456604\n",
      "Epoch: 143\t Train Loss: 0.5514456033706665\t Validation Loss: 0.7794582843780518\n",
      "Epoch: 144\t Train Loss: 0.5514878630638123\t Validation Loss: 0.7809420824050903\n",
      "Epoch: 145\t Train Loss: 0.5514959096908569\t Validation Loss: 0.7802017331123352\n",
      "Epoch: 146\t Train Loss: 0.5514575839042664\t Validation Loss: 0.7877829670906067\n",
      "Epoch: 147\t Train Loss: 0.5514464974403381\t Validation Loss: 0.7938970327377319\n",
      "Epoch: 148\t Train Loss: 0.5514476299285889\t Validation Loss: 0.7839986681938171\n",
      "Epoch: 149\t Train Loss: 0.5515038967132568\t Validation Loss: 0.782512903213501\n",
      "Epoch: 150\t Train Loss: 0.551444947719574\t Validation Loss: 0.7971165776252747\n",
      "Epoch: 151\t Train Loss: 0.5514602065086365\t Validation Loss: 0.800489068031311\n",
      "Epoch: 152\t Train Loss: 0.5514464974403381\t Validation Loss: 0.7881830334663391\n",
      "Epoch: 153\t Train Loss: 0.5514478087425232\t Validation Loss: 0.7854484915733337\n",
      "Epoch: 154\t Train Loss: 0.5514716506004333\t Validation Loss: 0.7990822196006775\n",
      "Epoch: 155\t Train Loss: 0.5514494776725769\t Validation Loss: 0.8003071546554565\n",
      "Epoch: 156\t Train Loss: 0.5514454245567322\t Validation Loss: 0.7969791889190674\n",
      "Epoch: 157\t Train Loss: 0.551542341709137\t Validation Loss: 0.7882022261619568\n",
      "Epoch: 158\t Train Loss: 0.5514475703239441\t Validation Loss: 0.7940314412117004\n",
      "Epoch: 159\t Train Loss: 0.5514627695083618\t Validation Loss: 0.7865641713142395\n",
      "Epoch: 160\t Train Loss: 0.5514475107192993\t Validation Loss: 0.7885693907737732\n",
      "Epoch: 161\t Train Loss: 0.5514489412307739\t Validation Loss: 0.8006370663642883\n",
      "Epoch: 162\t Train Loss: 0.5514459609985352\t Validation Loss: 0.8143240213394165\n",
      "Epoch: 163\t Train Loss: 0.5514477491378784\t Validation Loss: 0.7969319224357605\n",
      "Epoch: 164\t Train Loss: 0.5514479279518127\t Validation Loss: 0.8001606464385986\n",
      "Epoch: 165\t Train Loss: 0.5514456629753113\t Validation Loss: 0.7850964665412903\n",
      "Epoch: 166\t Train Loss: 0.5514785647392273\t Validation Loss: 0.7927228808403015\n",
      "Epoch: 167\t Train Loss: 0.5514518618583679\t Validation Loss: 0.7813732028007507\n",
      "Epoch: 168\t Train Loss: 0.551448404788971\t Validation Loss: 0.7961887121200562\n",
      "Epoch: 169\t Train Loss: 0.5514463186264038\t Validation Loss: 0.784966230392456\n",
      "Epoch: 170\t Train Loss: 0.5515037178993225\t Validation Loss: 0.811914324760437\n",
      "Epoch: 171\t Train Loss: 0.5514524579048157\t Validation Loss: 0.7850742340087891\n",
      "Epoch: 172\t Train Loss: 0.5514790415763855\t Validation Loss: 0.7945353388786316\n",
      "Epoch: 173\t Train Loss: 0.5514865517616272\t Validation Loss: 0.7919400930404663\n",
      "Epoch: 174\t Train Loss: 0.5514521598815918\t Validation Loss: 0.7825693488121033\n",
      "Epoch: 175\t Train Loss: 0.5514456033706665\t Validation Loss: 0.7852452397346497\n",
      "Epoch: 176\t Train Loss: 0.5514614582061768\t Validation Loss: 0.7933005690574646\n",
      "Epoch: 177\t Train Loss: 0.5514669418334961\t Validation Loss: 0.7958658337593079\n",
      "Epoch: 178\t Train Loss: 0.5515069961547852\t Validation Loss: 0.7914347052574158\n",
      "Epoch: 179\t Train Loss: 0.5514480471611023\t Validation Loss: 0.7917670607566833\n",
      "Epoch: 180\t Train Loss: 0.5514477491378784\t Validation Loss: 0.8031781315803528\n",
      "Epoch: 181\t Train Loss: 0.5514461398124695\t Validation Loss: 0.7936347126960754\n",
      "Epoch: 182\t Train Loss: 0.5525256395339966\t Validation Loss: 0.7889723181724548\n",
      "Epoch: 183\t Train Loss: 0.5514460802078247\t Validation Loss: 0.7899141907691956\n",
      "Epoch: 184\t Train Loss: 0.5514457821846008\t Validation Loss: 0.816331684589386\n",
      "Epoch: 185\t Train Loss: 0.5516203045845032\t Validation Loss: 0.8120471835136414\n",
      "Epoch: 186\t Train Loss: 0.5514451265335083\t Validation Loss: 0.8087338209152222\n",
      "Epoch: 187\t Train Loss: 0.5515914559364319\t Validation Loss: 0.8016027212142944\n",
      "Epoch: 188\t Train Loss: 0.551444947719574\t Validation Loss: 0.8103195428848267\n",
      "Epoch: 189\t Train Loss: 0.5514528751373291\t Validation Loss: 0.7739640474319458\n",
      "Epoch: 190\t Train Loss: 0.5514472723007202\t Validation Loss: 0.789562463760376\n",
      "Epoch: 191\t Train Loss: 0.5514500737190247\t Validation Loss: 0.787397027015686\n",
      "Epoch: 192\t Train Loss: 0.5515178442001343\t Validation Loss: 0.7906194925308228\n",
      "Epoch: 193\t Train Loss: 0.5514925122261047\t Validation Loss: 0.7938677072525024\n",
      "Epoch: 194\t Train Loss: 0.5515174269676208\t Validation Loss: 0.7945533990859985\n",
      "Epoch: 195\t Train Loss: 0.5515382885932922\t Validation Loss: 0.791556715965271\n",
      "Epoch: 196\t Train Loss: 0.5514453053474426\t Validation Loss: 0.8016591668128967\n",
      "Epoch: 197\t Train Loss: 0.5514572262763977\t Validation Loss: 0.7979984283447266\n",
      "Epoch: 198\t Train Loss: 0.5514451265335083\t Validation Loss: 0.7926088571548462\n",
      "Epoch: 199\t Train Loss: 0.5514459609985352\t Validation Loss: 0.79783695936203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<elmo_on_md.evaluation.sentiment_analysis.SentimentAnalysis at 0x23a21446198>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo = load_model('original', batch_size = 32)\n",
    "sentiment = SentimentAnalysis(elmo,lr=1e-4)\n",
    "\n",
    "sentiment.train(train_set,validate_set,n_epochs=200, batch_size = 64, tb_dir='baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:41:19.556066Z",
     "start_time": "2019-08-30T08:41:04.662452Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-30 11:41:09,505 INFO: 80 batches, avg len: 17.1\n",
      "2019-08-30 11:41:13,236 INFO: Finished 1000 sentences.\n",
      "2019-08-30 11:41:16,681 INFO: Finished 2000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1505  178   15]\n",
      " [ 105  669   16]\n",
      " [  17   23   32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.93      0.89      0.91      1698\n",
      "    negative       0.77      0.85      0.81       790\n",
      "     neutral       0.51      0.44      0.47        72\n",
      "\n",
      "    accuracy                           0.86      2560\n",
      "   macro avg       0.73      0.73      0.73      2560\n",
      "weighted avg       0.87      0.86      0.86      2560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train_preds = sentiment.predict(sentiment_data['train'])\n",
    "# print(confusion_matrix(sentiment_data['train']['labels'],train_preds))\n",
    "y_pred = sentiment.predict(sentiment_data['test'])\n",
    "y_true = sentiment_data['test']['labels']\n",
    "\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "print(classification_report(y_true, y_pred, target_names=['positive','negative','neutral']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:48:39.831606Z",
     "start_time": "2019-08-30T08:41:55.876390Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-30 11:42:14,912 INFO: 129 batches, avg len: 16.9\n",
      "2019-08-30 11:42:18,289 INFO: Finished 1000 sentences.\n",
      "2019-08-30 11:42:20,587 INFO: Finished 2000 sentences.\n",
      "2019-08-30 11:42:22,430 INFO: Finished 3000 sentences.\n",
      "2019-08-30 11:42:24,966 INFO: Finished 4000 sentences.\n",
      "2019-08-30 11:42:27,043 INFO: Finished 5000 sentences.\n",
      "2019-08-30 11:42:29,027 INFO: Finished 6000 sentences.\n",
      "2019-08-30 11:42:31,315 INFO: Finished 7000 sentences.\n",
      "2019-08-30 11:42:34,019 INFO: Finished 8000 sentences.\n",
      "2019-08-30 11:42:38,765 INFO: 33 batches, avg len: 17.2\n",
      "2019-08-30 11:42:41,449 INFO: Finished 1000 sentences.\n",
      "2019-08-30 11:42:43,643 INFO: Finished 2000 sentences.\n",
      "..\\elmo_on_md\\evaluation\\sentiment_analysis.py:65: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.softmax(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\t Train Loss: 1.278416633605957\t Validation Loss: 0.9915648102760315\n",
      "Epoch: 1\t Train Loss: 1.2893081903457642\t Validation Loss: 0.8957425951957703\n",
      "Epoch: 2\t Train Loss: 1.154569387435913\t Validation Loss: 0.8686726689338684\n",
      "Epoch: 3\t Train Loss: 0.8989688158035278\t Validation Loss: 0.8545435667037964\n",
      "Epoch: 4\t Train Loss: 0.60067218542099\t Validation Loss: 0.8538553714752197\n",
      "Epoch: 5\t Train Loss: 0.6054528951644897\t Validation Loss: 0.8255987763404846\n",
      "Epoch: 6\t Train Loss: 0.5649961829185486\t Validation Loss: 0.8317887187004089\n",
      "Epoch: 7\t Train Loss: 0.5590201020240784\t Validation Loss: 0.8651028871536255\n",
      "Epoch: 8\t Train Loss: 0.565280556678772\t Validation Loss: 0.8863596320152283\n",
      "Epoch: 9\t Train Loss: 0.5617823004722595\t Validation Loss: 0.873504638671875\n",
      "Epoch: 10\t Train Loss: 0.566034734249115\t Validation Loss: 0.8939685225486755\n",
      "Epoch: 11\t Train Loss: 0.5574159026145935\t Validation Loss: 0.8642645478248596\n",
      "Epoch: 12\t Train Loss: 0.5571596622467041\t Validation Loss: 0.880649745464325\n",
      "Epoch: 13\t Train Loss: 0.5548785328865051\t Validation Loss: 0.8833969831466675\n",
      "Epoch: 14\t Train Loss: 0.5590816140174866\t Validation Loss: 0.8897701501846313\n",
      "Epoch: 15\t Train Loss: 0.5579348206520081\t Validation Loss: 0.8812370300292969\n",
      "Epoch: 16\t Train Loss: 0.5532922148704529\t Validation Loss: 0.8710057735443115\n",
      "Epoch: 17\t Train Loss: 0.5540415644645691\t Validation Loss: 0.86576247215271\n",
      "Epoch: 18\t Train Loss: 0.5529347658157349\t Validation Loss: 0.85326087474823\n",
      "Epoch: 19\t Train Loss: 0.557181179523468\t Validation Loss: 0.8486899733543396\n",
      "Epoch: 20\t Train Loss: 0.5528914332389832\t Validation Loss: 0.8567891120910645\n",
      "Epoch: 21\t Train Loss: 0.5526764392852783\t Validation Loss: 0.8408239483833313\n",
      "Epoch: 22\t Train Loss: 0.5520878434181213\t Validation Loss: 0.8264501690864563\n",
      "Epoch: 23\t Train Loss: 0.5517295002937317\t Validation Loss: 0.8312020301818848\n",
      "Epoch: 24\t Train Loss: 0.5535148978233337\t Validation Loss: 0.8373355269432068\n",
      "Epoch: 25\t Train Loss: 0.5518093109130859\t Validation Loss: 0.8562291860580444\n",
      "Epoch: 26\t Train Loss: 0.5515611171722412\t Validation Loss: 0.8473408222198486\n",
      "Epoch: 27\t Train Loss: 0.5516737103462219\t Validation Loss: 0.8542447090148926\n",
      "Epoch: 28\t Train Loss: 0.551484227180481\t Validation Loss: 0.8781766295433044\n",
      "Epoch: 29\t Train Loss: 0.5526267290115356\t Validation Loss: 0.888048529624939\n",
      "Epoch: 30\t Train Loss: 0.5515663027763367\t Validation Loss: 0.8729114532470703\n",
      "Epoch: 31\t Train Loss: 0.5517697334289551\t Validation Loss: 0.8354859352111816\n",
      "Epoch: 32\t Train Loss: 0.5516995787620544\t Validation Loss: 0.8542519211769104\n",
      "Epoch: 33\t Train Loss: 0.5515201091766357\t Validation Loss: 0.8217044472694397\n",
      "Epoch: 34\t Train Loss: 0.5516266226768494\t Validation Loss: 0.8562023639678955\n",
      "Epoch: 35\t Train Loss: 0.5515649318695068\t Validation Loss: 0.8583282828330994\n",
      "Epoch: 36\t Train Loss: 0.5515502095222473\t Validation Loss: 0.8567893505096436\n",
      "Epoch: 37\t Train Loss: 0.5534369349479675\t Validation Loss: 0.8543376922607422\n",
      "Epoch: 38\t Train Loss: 0.5514633655548096\t Validation Loss: 0.8732877969741821\n",
      "Epoch: 39\t Train Loss: 0.5515082478523254\t Validation Loss: 0.8301905989646912\n",
      "Epoch: 40\t Train Loss: 0.5514952540397644\t Validation Loss: 0.8647974133491516\n",
      "Epoch: 41\t Train Loss: 0.5517823696136475\t Validation Loss: 0.8397179841995239\n",
      "Epoch: 42\t Train Loss: 0.5515289902687073\t Validation Loss: 0.8499476909637451\n",
      "Epoch: 43\t Train Loss: 0.5514770746231079\t Validation Loss: 0.8490929007530212\n",
      "Epoch: 44\t Train Loss: 0.5526901483535767\t Validation Loss: 0.8299844861030579\n",
      "Epoch: 45\t Train Loss: 0.5515457987785339\t Validation Loss: 0.8442732095718384\n",
      "Epoch: 46\t Train Loss: 0.5516256093978882\t Validation Loss: 0.8223140835762024\n",
      "Epoch: 47\t Train Loss: 0.5514810085296631\t Validation Loss: 0.8366758227348328\n",
      "Epoch: 48\t Train Loss: 0.5514604449272156\t Validation Loss: 0.8393162488937378\n",
      "Epoch: 49\t Train Loss: 0.5514808297157288\t Validation Loss: 0.867516279220581\n",
      "Epoch: 50\t Train Loss: 0.5514541268348694\t Validation Loss: 0.8344370126724243\n",
      "Epoch: 51\t Train Loss: 0.5514838695526123\t Validation Loss: 0.8292797803878784\n",
      "Epoch: 52\t Train Loss: 0.5514638423919678\t Validation Loss: 0.8394527435302734\n",
      "Epoch: 53\t Train Loss: 0.5514755845069885\t Validation Loss: 0.8474734425544739\n",
      "Epoch: 54\t Train Loss: 0.5514600276947021\t Validation Loss: 0.8294137716293335\n",
      "Epoch: 55\t Train Loss: 0.5514655113220215\t Validation Loss: 0.8179760575294495\n",
      "Epoch: 56\t Train Loss: 0.5514631271362305\t Validation Loss: 0.796902060508728\n",
      "Epoch: 57\t Train Loss: 0.551455557346344\t Validation Loss: 0.8479507565498352\n",
      "Epoch: 58\t Train Loss: 0.5516617298126221\t Validation Loss: 0.852857768535614\n",
      "Epoch: 59\t Train Loss: 0.5520620346069336\t Validation Loss: 0.855153501033783\n",
      "Epoch: 60\t Train Loss: 0.5515059232711792\t Validation Loss: 0.8538901805877686\n",
      "Epoch: 61\t Train Loss: 0.5515851974487305\t Validation Loss: 0.839611828327179\n",
      "Epoch: 62\t Train Loss: 0.5515058636665344\t Validation Loss: 0.8429426550865173\n",
      "Epoch: 63\t Train Loss: 0.5514740943908691\t Validation Loss: 0.8432637453079224\n",
      "Epoch: 64\t Train Loss: 0.5516669750213623\t Validation Loss: 0.8449835181236267\n",
      "Epoch: 65\t Train Loss: 0.5514543652534485\t Validation Loss: 0.8555701971054077\n",
      "Epoch: 66\t Train Loss: 0.551496684551239\t Validation Loss: 0.8642883896827698\n",
      "Epoch: 67\t Train Loss: 0.5514715313911438\t Validation Loss: 0.8531748056411743\n",
      "Epoch: 68\t Train Loss: 0.551502525806427\t Validation Loss: 0.8510220050811768\n",
      "Epoch: 69\t Train Loss: 0.5514590740203857\t Validation Loss: 0.8621619939804077\n",
      "Epoch: 70\t Train Loss: 0.5519833564758301\t Validation Loss: 0.8549314141273499\n",
      "Epoch: 71\t Train Loss: 0.5514525175094604\t Validation Loss: 0.8460177183151245\n",
      "Epoch: 72\t Train Loss: 0.5514769554138184\t Validation Loss: 0.8544455170631409\n",
      "Epoch: 73\t Train Loss: 0.5514578819274902\t Validation Loss: 0.8554069399833679\n",
      "Epoch: 74\t Train Loss: 0.5514522194862366\t Validation Loss: 0.860195517539978\n",
      "Epoch: 75\t Train Loss: 0.5514575242996216\t Validation Loss: 0.8317164778709412\n",
      "Epoch: 76\t Train Loss: 0.5514620542526245\t Validation Loss: 0.8281813263893127\n",
      "Epoch: 77\t Train Loss: 0.5514526963233948\t Validation Loss: 0.8465931415557861\n",
      "Epoch: 78\t Train Loss: 0.5514686107635498\t Validation Loss: 0.8475328683853149\n",
      "Epoch: 79\t Train Loss: 0.551445484161377\t Validation Loss: 0.8461448550224304\n",
      "Epoch: 80\t Train Loss: 0.5514769554138184\t Validation Loss: 0.8257814049720764\n",
      "Epoch: 81\t Train Loss: 0.5514453649520874\t Validation Loss: 0.8400151133537292\n",
      "Epoch: 82\t Train Loss: 0.5514665246009827\t Validation Loss: 0.835710346698761\n",
      "Epoch: 83\t Train Loss: 0.5514482855796814\t Validation Loss: 0.839454710483551\n",
      "Epoch: 84\t Train Loss: 0.5514615178108215\t Validation Loss: 0.858898937702179\n",
      "Epoch: 85\t Train Loss: 0.5516060590744019\t Validation Loss: 0.8524423837661743\n",
      "Epoch: 86\t Train Loss: 0.5514547228813171\t Validation Loss: 0.8559607267379761\n",
      "Epoch: 87\t Train Loss: 0.5514484643936157\t Validation Loss: 0.836298942565918\n",
      "Epoch: 88\t Train Loss: 0.5515314936637878\t Validation Loss: 0.8379393219947815\n",
      "Epoch: 89\t Train Loss: 0.5514565706253052\t Validation Loss: 0.8514784574508667\n",
      "Epoch: 90\t Train Loss: 0.5514456629753113\t Validation Loss: 0.8462893962860107\n",
      "Epoch: 91\t Train Loss: 0.551588237285614\t Validation Loss: 0.8675429821014404\n",
      "Epoch: 92\t Train Loss: 0.5515438914299011\t Validation Loss: 0.842186450958252\n",
      "Epoch: 93\t Train Loss: 0.5514534115791321\t Validation Loss: 0.8479865789413452\n",
      "Epoch: 94\t Train Loss: 0.5514454245567322\t Validation Loss: 0.8439697027206421\n",
      "Epoch: 95\t Train Loss: 0.5514785647392273\t Validation Loss: 0.8282583951950073\n",
      "Epoch: 96\t Train Loss: 0.5514491200447083\t Validation Loss: 0.842598557472229\n",
      "Epoch: 97\t Train Loss: 0.5514973998069763\t Validation Loss: 0.8409615755081177\n",
      "Epoch: 98\t Train Loss: 0.5514724254608154\t Validation Loss: 0.8371698260307312\n",
      "Epoch: 99\t Train Loss: 0.5514457821846008\t Validation Loss: 0.8544787168502808\n",
      "Epoch: 100\t Train Loss: 0.5514556169509888\t Validation Loss: 0.8452761769294739\n",
      "Epoch: 101\t Train Loss: 0.5514498949050903\t Validation Loss: 0.8490995764732361\n",
      "Epoch: 102\t Train Loss: 0.551476776599884\t Validation Loss: 0.8391436338424683\n",
      "Epoch: 103\t Train Loss: 0.5514549016952515\t Validation Loss: 0.8496735692024231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104\t Train Loss: 0.5514453053474426\t Validation Loss: 0.8426187038421631\n",
      "Epoch: 105\t Train Loss: 0.5514470934867859\t Validation Loss: 0.8537213802337646\n",
      "Epoch: 106\t Train Loss: 0.5514490604400635\t Validation Loss: 0.8516772389411926\n",
      "Epoch: 107\t Train Loss: 0.5514452457427979\t Validation Loss: 0.8479706048965454\n",
      "Epoch: 108\t Train Loss: 0.5514592528343201\t Validation Loss: 0.8502740859985352\n",
      "Epoch: 109\t Train Loss: 0.5515186786651611\t Validation Loss: 0.8617008328437805\n",
      "Epoch: 110\t Train Loss: 0.5514453053474426\t Validation Loss: 0.8458512425422668\n",
      "Epoch: 111\t Train Loss: 0.551447868347168\t Validation Loss: 0.8552643060684204\n",
      "Epoch: 112\t Train Loss: 0.5515409708023071\t Validation Loss: 0.8007053732872009\n",
      "Epoch: 113\t Train Loss: 0.5514780879020691\t Validation Loss: 0.8411164283752441\n",
      "Epoch: 114\t Train Loss: 0.5514653921127319\t Validation Loss: 0.8619568943977356\n",
      "Epoch: 115\t Train Loss: 0.5514633655548096\t Validation Loss: 0.8406601548194885\n",
      "Epoch: 116\t Train Loss: 0.5514550805091858\t Validation Loss: 0.8536730408668518\n",
      "Epoch: 117\t Train Loss: 0.5531362891197205\t Validation Loss: 0.8467468619346619\n",
      "Epoch: 118\t Train Loss: 0.5514686107635498\t Validation Loss: 0.8274863362312317\n",
      "Epoch: 119\t Train Loss: 0.5515418648719788\t Validation Loss: 0.8356198668479919\n",
      "Epoch: 120\t Train Loss: 0.5514553785324097\t Validation Loss: 0.8445766568183899\n",
      "Epoch: 121\t Train Loss: 0.551534116268158\t Validation Loss: 0.840573251247406\n",
      "Epoch: 122\t Train Loss: 0.5514467358589172\t Validation Loss: 0.835563600063324\n",
      "Epoch: 123\t Train Loss: 0.551449179649353\t Validation Loss: 0.8482185006141663\n",
      "Epoch: 124\t Train Loss: 0.5514470934867859\t Validation Loss: 0.8336441516876221\n",
      "Epoch: 125\t Train Loss: 0.5515042543411255\t Validation Loss: 0.8326990604400635\n",
      "Epoch: 126\t Train Loss: 0.5514643788337708\t Validation Loss: 0.8443192839622498\n",
      "Epoch: 127\t Train Loss: 0.5515238046646118\t Validation Loss: 0.8315730094909668\n",
      "Epoch: 128\t Train Loss: 0.5515037775039673\t Validation Loss: 0.847659707069397\n",
      "Epoch: 129\t Train Loss: 0.5514487028121948\t Validation Loss: 0.8487797975540161\n",
      "Epoch: 130\t Train Loss: 0.5514463186264038\t Validation Loss: 0.8566792607307434\n",
      "Epoch: 131\t Train Loss: 0.551460325717926\t Validation Loss: 0.8504273891448975\n",
      "Epoch: 132\t Train Loss: 0.5514655709266663\t Validation Loss: 0.8393123745918274\n",
      "Epoch: 133\t Train Loss: 0.551445484161377\t Validation Loss: 0.834019660949707\n",
      "Epoch: 134\t Train Loss: 0.5514456033706665\t Validation Loss: 0.8420690894126892\n",
      "Epoch: 135\t Train Loss: 0.5515584349632263\t Validation Loss: 0.8540911078453064\n",
      "Epoch: 136\t Train Loss: 0.5514464378356934\t Validation Loss: 0.8191360831260681\n",
      "Epoch: 137\t Train Loss: 0.5514485836029053\t Validation Loss: 0.8592691421508789\n",
      "Epoch: 138\t Train Loss: 0.5514852404594421\t Validation Loss: 0.8418734669685364\n",
      "Epoch: 139\t Train Loss: 0.5514571666717529\t Validation Loss: 0.8684280514717102\n",
      "Epoch: 140\t Train Loss: 0.5514593720436096\t Validation Loss: 0.8339937329292297\n",
      "Epoch: 141\t Train Loss: 0.5514516830444336\t Validation Loss: 0.8391203880310059\n",
      "Epoch: 142\t Train Loss: 0.5514451861381531\t Validation Loss: 0.8314828276634216\n",
      "Epoch: 143\t Train Loss: 0.5514755845069885\t Validation Loss: 0.8380572199821472\n",
      "Epoch: 144\t Train Loss: 0.5514459609985352\t Validation Loss: 0.837047815322876\n",
      "Epoch: 145\t Train Loss: 0.5514459609985352\t Validation Loss: 0.8272354006767273\n",
      "Epoch: 146\t Train Loss: 0.5514471530914307\t Validation Loss: 0.8326323628425598\n",
      "Epoch: 147\t Train Loss: 0.551446795463562\t Validation Loss: 0.8388477563858032\n",
      "Epoch: 148\t Train Loss: 0.5514559149742126\t Validation Loss: 0.8373578190803528\n",
      "Epoch: 149\t Train Loss: 0.5514448285102844\t Validation Loss: 0.8403258323669434\n",
      "Epoch: 150\t Train Loss: 0.5514676570892334\t Validation Loss: 0.8388190865516663\n",
      "Epoch: 151\t Train Loss: 0.551446795463562\t Validation Loss: 0.8366690278053284\n",
      "Epoch: 152\t Train Loss: 0.5514534115791321\t Validation Loss: 0.8551114201545715\n",
      "Epoch: 153\t Train Loss: 0.5514459609985352\t Validation Loss: 0.8419297933578491\n",
      "Epoch: 154\t Train Loss: 0.551460862159729\t Validation Loss: 0.8364492654800415\n",
      "Epoch: 155\t Train Loss: 0.5514489412307739\t Validation Loss: 0.8442384600639343\n",
      "Epoch: 156\t Train Loss: 0.5514475107192993\t Validation Loss: 0.8227306604385376\n",
      "Epoch: 157\t Train Loss: 0.5514459013938904\t Validation Loss: 0.8446455597877502\n",
      "Epoch: 158\t Train Loss: 0.5514500737190247\t Validation Loss: 0.8398373126983643\n",
      "Epoch: 159\t Train Loss: 0.551445484161377\t Validation Loss: 0.848075270652771\n",
      "Epoch: 160\t Train Loss: 0.5514472723007202\t Validation Loss: 0.8597507476806641\n",
      "Epoch: 161\t Train Loss: 0.5514475107192993\t Validation Loss: 0.8611419200897217\n",
      "Epoch: 162\t Train Loss: 0.5514570474624634\t Validation Loss: 0.8703052401542664\n",
      "Epoch: 163\t Train Loss: 0.5514546036720276\t Validation Loss: 0.8547826409339905\n",
      "Epoch: 164\t Train Loss: 0.5514456629753113\t Validation Loss: 0.8447233438491821\n",
      "Epoch: 165\t Train Loss: 0.5514488220214844\t Validation Loss: 0.8383803963661194\n",
      "Epoch: 166\t Train Loss: 0.5514459609985352\t Validation Loss: 0.8562770485877991\n",
      "Epoch: 167\t Train Loss: 0.5514485836029053\t Validation Loss: 0.8346956968307495\n",
      "Epoch: 168\t Train Loss: 0.5514556169509888\t Validation Loss: 0.843766450881958\n",
      "Epoch: 169\t Train Loss: 0.551445484161377\t Validation Loss: 0.8545619249343872\n",
      "Epoch: 170\t Train Loss: 0.5514472723007202\t Validation Loss: 0.8720754384994507\n",
      "Epoch: 171\t Train Loss: 0.5514456033706665\t Validation Loss: 0.8355990052223206\n",
      "Epoch: 172\t Train Loss: 0.5514473915100098\t Validation Loss: 0.8647632002830505\n",
      "Epoch: 173\t Train Loss: 0.5514457821846008\t Validation Loss: 0.8444165587425232\n",
      "Epoch: 174\t Train Loss: 0.5514982342720032\t Validation Loss: 0.8460160493850708\n",
      "Epoch: 175\t Train Loss: 0.5514448285102844\t Validation Loss: 0.8343320488929749\n",
      "Epoch: 176\t Train Loss: 0.5514471530914307\t Validation Loss: 0.8429294228553772\n",
      "Epoch: 177\t Train Loss: 0.5514775514602661\t Validation Loss: 0.8387737274169922\n",
      "Epoch: 178\t Train Loss: 0.5514451861381531\t Validation Loss: 0.8369287252426147\n",
      "Epoch: 179\t Train Loss: 0.5514457821846008\t Validation Loss: 0.8421507477760315\n",
      "Epoch: 180\t Train Loss: 0.5514453053474426\t Validation Loss: 0.8436504602432251\n",
      "Epoch: 181\t Train Loss: 0.551444947719574\t Validation Loss: 0.8213392496109009\n",
      "Epoch: 182\t Train Loss: 0.551444947719574\t Validation Loss: 0.835162341594696\n",
      "Epoch: 183\t Train Loss: 0.5514448285102844\t Validation Loss: 0.8307052254676819\n",
      "Epoch: 184\t Train Loss: 0.5514448285102844\t Validation Loss: 0.8424432873725891\n",
      "Epoch: 185\t Train Loss: 0.5514453053474426\t Validation Loss: 0.8349015116691589\n",
      "Epoch: 186\t Train Loss: 0.5514643788337708\t Validation Loss: 0.8522523641586304\n",
      "Epoch: 187\t Train Loss: 0.5514451861381531\t Validation Loss: 0.8452658653259277\n",
      "Epoch: 188\t Train Loss: 0.5902746319770813\t Validation Loss: 0.8100124001502991\n",
      "Epoch: 189\t Train Loss: 0.5514853596687317\t Validation Loss: 0.7754106521606445\n",
      "Epoch: 190\t Train Loss: 0.5514870285987854\t Validation Loss: 0.8637098670005798\n",
      "Epoch: 191\t Train Loss: 0.5514478087425232\t Validation Loss: 0.8327926993370056\n",
      "Epoch: 192\t Train Loss: 0.5515156984329224\t Validation Loss: 0.8362454771995544\n",
      "Epoch: 193\t Train Loss: 0.5514471530914307\t Validation Loss: 0.842718243598938\n",
      "Epoch: 194\t Train Loss: 0.5516089200973511\t Validation Loss: 0.8514459729194641\n",
      "Epoch: 195\t Train Loss: 0.5542448163032532\t Validation Loss: 0.8387504816055298\n",
      "Epoch: 196\t Train Loss: 0.5514487028121948\t Validation Loss: 0.8402032852172852\n",
      "Epoch: 197\t Train Loss: 0.5514469742774963\t Validation Loss: 0.8323277831077576\n",
      "Epoch: 198\t Train Loss: 0.5514582395553589\t Validation Loss: 0.8457508087158203\n",
      "Epoch: 199\t Train Loss: 0.5514466166496277\t Validation Loss: 0.8437507152557373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<elmo_on_md.evaluation.sentiment_analysis.SentimentAnalysis at 0x1f02fc16a90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo = load_model('pos_weight8_lr-4_new_tags_30epochs', batch_size = 32)\n",
    "sentiment = SentimentAnalysis(elmo,lr=1e-4)\n",
    "\n",
    "sentiment.train(train_set,validate_set,n_epochs=200, batch_size = 64, tb_dir='new_elmo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T08:48:51.232442Z",
     "start_time": "2019-08-30T08:48:39.832606Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-30 11:48:44,717 INFO: 40 batches, avg len: 17.1\n",
      "2019-08-30 11:48:46,674 INFO: Finished 1000 sentences.\n",
      "2019-08-30 11:48:49,457 INFO: Finished 2000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1506  175   17]\n",
      " [ 142  626   22]\n",
      " [  23   18   31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.90      0.89      0.89      1698\n",
      "    negative       0.76      0.79      0.78       790\n",
      "     neutral       0.44      0.43      0.44        72\n",
      "\n",
      "    accuracy                           0.84      2560\n",
      "   macro avg       0.70      0.70      0.70      2560\n",
      "weighted avg       0.85      0.84      0.85      2560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = sentiment.predict(sentiment_data['test'])\n",
    "y_true = sentiment_data['test']['labels']\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, target_names=['positive','negative','neutral']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
