{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('../')\n",
    "\n",
    "from typing import List,Dict\n",
    "from elmo_on_md.data_loaders.sentiment_loader import SentimentLoader\n",
    "from elmo_on_md.evaluation.sentiment_analysis import SentimentAnalysis\n",
    "from elmo_on_md.evaluation.model_loader import load_model\n",
    "from ELMoForManyLangs.elmoformanylangs import Embedder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = SentimentLoader()\n",
    "sentiment_data = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-24 11:16:47,536 INFO: char embedding size: 2289\n",
      "2019-08-24 11:16:48,598 INFO: word embedding size: 189561\n",
      "2019-08-24 11:16:52,584 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(189561, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(2289, 50, padding_idx=2286)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-24 11:17:12,649 INFO: 129 batches, avg len: 16.9\n",
      "2019-08-24 11:18:28,413 INFO: Finished 1000 sentences.\n",
      "2019-08-24 11:19:21,534 INFO: Finished 2000 sentences.\n",
      "2019-08-24 11:20:13,563 INFO: Finished 3000 sentences.\n",
      "2019-08-24 11:21:08,258 INFO: Finished 4000 sentences.\n",
      "2019-08-24 11:21:51,290 INFO: Finished 5000 sentences.\n",
      "2019-08-24 11:22:47,686 INFO: Finished 6000 sentences.\n",
      "2019-08-24 11:24:03,224 INFO: Finished 7000 sentences.\n",
      "2019-08-24 11:24:39,775 INFO: Finished 8000 sentences.\n",
      "2019-08-24 11:24:56,615 INFO: 33 batches, avg len: 17.2\n",
      "2019-08-24 11:25:53,767 INFO: Finished 1000 sentences.\n",
      "2019-08-24 11:26:47,531 INFO: Finished 2000 sentences.\n",
      "..\\elmo_on_md\\evaluation\\sentiment_analysis.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.softmax(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\t Train Loss: 419.94457018375397\t Validation Loss: 1.0549752712249756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t Train Loss: 383.03655964136124\t Validation Loss: 0.9633446335792542\n",
      "Epoch: 2\t Train Loss: 352.7519838809967\t Validation Loss: 0.8901171684265137\n",
      "Epoch: 3\t Train Loss: 323.40446269512177\t Validation Loss: 0.8467468619346619\n",
      "Epoch: 4\t Train Loss: 308.2876083254814\t Validation Loss: 0.8341546058654785\n",
      "Epoch: 5\t Train Loss: 295.0287689566612\t Validation Loss: 0.8409781455993652\n",
      "Epoch: 6\t Train Loss: 286.3600198030472\t Validation Loss: 0.8232043981552124\n",
      "Epoch: 7\t Train Loss: 279.4992669224739\t Validation Loss: 0.8118706941604614\n",
      "Epoch: 8\t Train Loss: 274.06674510240555\t Validation Loss: 0.8232394456863403\n",
      "Epoch: 9\t Train Loss: 276.1418382525444\t Validation Loss: 0.8122153282165527\n",
      "Epoch: 10\t Train Loss: 264.9942664504051\t Validation Loss: 0.8227456212043762\n",
      "Epoch: 11\t Train Loss: 261.77694940567017\t Validation Loss: 0.8319273591041565\n",
      "Epoch: 12\t Train Loss: 259.07076555490494\t Validation Loss: 0.8356425762176514\n",
      "Epoch: 13\t Train Loss: 257.74998039007187\t Validation Loss: 0.8325043320655823\n",
      "Epoch: 14\t Train Loss: 262.47095131874084\t Validation Loss: 0.8061155676841736\n",
      "Epoch: 15\t Train Loss: 255.15929156541824\t Validation Loss: 0.8266364932060242\n",
      "Epoch: 16\t Train Loss: 253.4850177168846\t Validation Loss: 0.8048826456069946\n",
      "Epoch: 17\t Train Loss: 252.12525862455368\t Validation Loss: 0.8073891997337341\n",
      "Epoch: 18\t Train Loss: 250.04725974798203\t Validation Loss: 0.8029181957244873\n",
      "Epoch: 19\t Train Loss: 248.4879954457283\t Validation Loss: 0.8186914324760437\n"
     ]
    }
   ],
   "source": [
    "\n",
    "elmo = load_model('original')\n",
    "sentiment = SentimentAnalysis(elmo,lr=1e-4)\n",
    "sentences = sentiment_data['train']['sentences']\n",
    "labels = sentiment_data['train']['labels']\n",
    "\n",
    "tokens_train,tokens_test, labels_train,labels_test = train_test_split(sentences, labels, test_size=0.2, random_state=1)\n",
    "\n",
    "train_set = {'sentences':tokens_train,'labels':labels_train}\n",
    "validate_set = {'sentences':tokens_test,'labels':labels_test}\n",
    "\n",
    "sentiment.train(train_set,validate_set,n_epochs=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = sentiment.predict(sentiment_data['train'])\n",
    "print(confusion_matrix(sentiment_data['train']['labels'],train_preds))\n",
    "test_preds = sentiment.predict(sentiment_data['test'])\n",
    "print(confusion_matrix(sentiment_data['test']['labels'],test_preds))\n",
    "from sklearn.metrics import precision_recall_fscore_support,classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support,classification_report\n",
    "print(classification_report(sentiment_data['train']['labels'],train_preds,target_names=['bad','neutral','good']))\n",
    "print(classification_report(sentiment_data['test']['labels'],test_preds,target_names=['bad','neutral','good']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentiment_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-61034dad15c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentiment_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_preds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bad'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'neutral'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'good'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sentiment_data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,classification_report\n",
    "print(classification_report(sentiment_data['train']['labels'],train_preds,target_names=['bad','neutral','good']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,classification_report\n",
    "print(classification_report(sentiment_data['test']['labels'],test_preds,target_names=['bad','neutral','good']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.train(train_set,validate_set,n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = sentiment.predict(sentiment_data['train'])\n",
    "print(confusion_matrix(sentiment_data['train']['labels'],train_preds))\n",
    "test_preds = sentiment.predict(sentiment_data['test'])\n",
    "print(confusion_matrix(sentiment_data['test']['labels'],test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.summary.event_accumulator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6bb50b406296>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevent_accumulator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEventAccumulator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.summary.event_accumulator'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.python.summary.event_accumulator import EventAccumulator\n",
    "\n",
    "\n",
    "log_file = \"D://Projects/events.out.tfevents.1566034114.DESKTOP-OE11P6R.5500.0\"\n",
    "plot_tensorflow_log(log_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
